{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Tricks\n",
    "> Refinements and Improvements to CNN's for image classification\n",
    "\n",
    "[Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/abs/1812.01187)\n",
    "\n",
    "Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, Mu Li\n",
    "\n",
    "    Much of the recent progress made in image classification research can be credited to training procedure refinements, such as changes in data augmentations and optimization methods. In the literature, however, most refinements are either briefly mentioned as implementation details or only visible in source code. In this paper, we will examine a collection of such refinements and empirically evaluate their impact on the final model accuracy through ablation study. We will show that, by combining these refinements together, we are able to improve various CNN models significantly. For example, we raise ResNet-50's top-1 validation accuracy from 75.3% to 79.29% on ImageNet. We will also demonstrate that improvement on image classification accuracy leads to better transfer learning performance in other application domains such as object detection and semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_09 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data to DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160) # downloads and returns a path to folder\n",
    "tfms = [make_rgb, ResizeFixed(128), to_byte_tensor, to_float_tensor] # transforms to be applied to images\n",
    "\n",
    "il = ImageList.from_files(path, tfms=tfms) # Imagelist from files\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name=\"val\")) # Splitdata by function\n",
    "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcesser()) # label the data by parent folder\n",
    "data = ll.to_databunch(bs, c_in=3, c_out=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [partial(AvgStatsCallback, accuracy), \n",
    "             CudaCallback,\n",
    "             partial(BatchTransformXCallback, norm_imagenette)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Arch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't use a big conv 7x7 at first but three 3x3 convs, and don't go directly from 3 channels to 64 but progressively add those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [64,64,128,256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def prev_pow_2(x): return 2**math.floor(math.log2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**math.floor(math.log2(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cnn_layers(data, nfs, layer, **kwargs):\n",
    "    \n",
    "    def f(ni, nf, stride=2): \n",
    "        return layer(ni, nf, ks=3, stride=stride, **kwargs)\n",
    "    \n",
    "    l1 = data.c_in\n",
    "    l2 = prev_pow_2(l1*3*3)\n",
    "    \n",
    "    layers = [f(l1,   l2,   stride=1),\n",
    "              f(l2,   l2*2, stride=2),\n",
    "              f(l2*2, l2*4, stride=2)]\n",
    "    nfs = [l2*4] + nfs\n",
    "    \n",
    "    layers += [f(nfs[i], nfs[i+1]) for i in range(len(nfs)-1)]\n",
    "    layers += [nn.AdaptiveAvgPool2d(1), Lambda(flatten), nn.Linear(nfs[-1], data.c_out)]\n",
    "    \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cnn_model(data, nfs, layer, **kwargs):\n",
    "    return nn.Sequential(*get_cnn_layers(data, nfs, layer, **kwargs))\n",
    "\n",
    "def get_learn_run(data, nfs, layer, lr, cbs=None, opt_func=None, uniform=False, **kwargs):\n",
    "    model = get_cnn_model(data, nfs, layer, **kwargs)\n",
    "    init_cnn(model, uniform=uniform)\n",
    "    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched = combine_scheds([0.3, 0.7], cos_1cycle_anneal(0.1, 0.3, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn, run = get_learn_run(data, nfs, conv_layer, lr=0.2, cbs=callbacks+[partial(ParamScheduler, 'lr', sched)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1.730062820123561, tensor(0.4031, device='cuda:0')]\n",
      "valid: [1.3776530155254778, tensor(0.5465, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function that would print out a summary of the layers and their activation shapes of our model would be very helpful. \n",
    "\n",
    "We can do this by using Hooks and sending batch through the model to print out what happens at every stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def model_summary(run, learn, data, find_all=False):\n",
    "    xb, yb = get_batch(data.valid_dl, run)\n",
    "    device = next(learn.model.parameters()).device\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "    hf = lambda hook,mod,inp,outp: print(f'{mod}\\nOutput:{outp.shape}\\n')\n",
    "    mods = find_mods(learn.model, is_lin_layer) if find_all else learn.model.children()\n",
    "    with Hooks(mods, hf) as hook: learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): GeneralRelu()\n",
      "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Output:torch.Size([128, 16, 128, 128])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): GeneralRelu()\n",
      "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Output:torch.Size([128, 32, 64, 64])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): GeneralRelu()\n",
      "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Output:torch.Size([128, 64, 32, 32])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): GeneralRelu()\n",
      "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Output:torch.Size([128, 64, 16, 16])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): GeneralRelu()\n",
      "  (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Output:torch.Size([128, 64, 8, 8])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): GeneralRelu()\n",
      "  (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Output:torch.Size([128, 128, 4, 4])\n",
      "\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): GeneralRelu()\n",
      "  (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Output:torch.Size([128, 256, 2, 2])\n",
      "\n",
      "AdaptiveAvgPool2d(output_size=1)\n",
      "Output:torch.Size([128, 256, 1, 1])\n",
      "\n",
      "Lambda()\n",
      "Output:torch.Size([128, 256])\n",
      "\n",
      "Linear(in_features=256, out_features=10, bias=True)\n",
      "Output:torch.Size([128, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_summary(run, learn, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [1.3123442697882564, tensor(0.5594, device='cuda:0')]\n",
      "valid: [1.5668453921178345, tensor(0.5029, device='cuda:0')]\n",
      "train: [1.2176354460938326, tensor(0.5961, device='cuda:0')]\n",
      "valid: [1.275376816281847, tensor(0.5735, device='cuda:0')]\n",
      "train: [0.8694145451605239, tensor(0.7151, device='cuda:0')]\n",
      "valid: [1.2902619924363057, tensor(0.5967, device='cuda:0')]\n",
      "train: [0.48882599634333085, tensor(0.8495, device='cuda:0')]\n",
      "valid: [1.1328984623805733, tensor(0.6566, device='cuda:0')]\n",
      "train: [0.2372632797648907, tensor(0.9434, device='cuda:0')]\n",
      "valid: [1.1539058767914012, tensor(0.6596, device='cuda:0')]\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(5, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSUV Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our bag of tricks model with the LSUV initialization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsuv_module(mod, xb, mdl):\n",
    "    h = Hook(mod, lsuv_append_stat)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if mod.bias is not None:\n",
    "            while mdl(xb) is not None and abs(h.mean ) > 1e-3: mod.bias -= h.mean\n",
    "        while mdl(xb) is not None and abs(h.std-1) > 1e-3: mod.weight.data /= h.std\n",
    "\n",
    "    h.remove()\n",
    "    return h.mean, h.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch(data.valid_dl, run)\n",
    "\n",
    "mods = find_mods(learn.model, is_lin_layer)\n",
    "for m in mods: lsuv_module(m, xb, learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.4784115642161263, tensor(0.8919, device='cuda:0')]\n",
      "valid: [1.4449001044984076, tensor(0.5753, device='cuda:0')]\n",
      "train: [0.6862207949130056, tensor(0.7698, device='cuda:0')]\n",
      "valid: [1.4064058767914012, tensor(0.5992, device='cuda:0')]\n",
      "train: [0.3569653328047444, tensor(0.8857, device='cuda:0')]\n",
      "valid: [1.3306855841958598, tensor(0.6334, device='cuda:0')]\n",
      "train: [0.10578015885719189, tensor(0.9776, device='cuda:0')]\n",
      "valid: [1.2797096437101911, tensor(0.6548, device='cuda:0')]\n",
      "train: [0.036571728690950406, tensor(0.9977, device='cuda:0')]\n",
      "valid: [1.2824068222531848, tensor(0.6555, device='cuda:0')]\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(5, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "{\n",
       "const ip = IPython.notebook\n",
       "if (ip) {\n",
       "    ip.save_notebook()\n",
       "    console.log('a')\n",
       "    const s = `!python notebook2script.py ${ip.notebook_name}`\n",
       "    if (ip.kernel) { ip.kernel.execute(s) }\n",
       "}\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_auto_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "270.825px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
