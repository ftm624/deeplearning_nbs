
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/08_batchnorm.ipynb

from exp.nb_07 import *

def init_cnn_(m, func):
    if isinstance(m, nn.Conv2d):
        func(m.weight, a=0.1)
        if getattr(m, 'bias', None) is not None: m.bias.data.zero_()
    for l in m.children(): init_cnn_(l, func)

def init_cnn(model, uniform=False):
    initzer = init.kaiming_normal_ if not uniform else init.kaiming_uniform_
    init_cnn_(model, initzer)

def get_learn_run(data, nfs, layer, lr, cbs=None, opt_func=None, uniform=False, **kwargs):
    model = get_cnn_model(data, nfs, layer, **kwargs)
    init_cnn(model, uniform=uniform)
    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)

def conv_layer(ni, nf, ks=3, stride=2, bn=True, **kwargs):
    # no bias if using bn
    layers = [nn.Conv2d(ni, nf, kernel_size=ks, padding=ks//2, stride=stride, bias=not bn), GeneralRelu(**kwargs)]
    if bn: layers.append(nn.BatchNorm2d(nf, eps=1e-05, momentum=0.1))
    return nn.Sequential(*layers)